"use strict";
Object.defineProperty(exports, "__esModule", { value: true });
exports.GeminiImageModel = void 0;
const core_1 = require("@aigne/core");
const type_utils_js_1 = require("@aigne/core/utils/type-utils.js");
const genai_1 = require("@google/genai");
const zod_1 = require("zod");
const DEFAULT_MODEL = "imagen-4.0-generate-001";
const geminiImageModelInputSchema = core_1.imageModelInputSchema.extend({});
const geminiImageModelOptionsSchema = zod_1.z.object({
    apiKey: zod_1.z.string().optional(),
    baseURL: zod_1.z.string().optional(),
    model: zod_1.z.string().optional(),
    modelOptions: zod_1.z.object({}).optional(),
    clientOptions: zod_1.z.object({}).optional(),
});
class GeminiImageModel extends core_1.ImageModel {
    options;
    constructor(options) {
        super({
            ...options,
            inputSchema: geminiImageModelInputSchema,
            description: options?.description ?? "Draw or edit image by Gemini image models",
        });
        this.options = options;
        if (options)
            (0, type_utils_js_1.checkArguments)(this.name, geminiImageModelOptionsSchema, options);
    }
    _client;
    apiKeyEnvName = "GEMINI_API_KEY";
    get client() {
        if (this._client)
            return this._client;
        const { apiKey } = this.credential;
        if (!apiKey)
            throw new Error(`${this.name} requires an API key. Please provide it via \`options.apiKey\`, or set the \`${this.apiKeyEnvName}\` environment variable`);
        this._client ??= new genai_1.GoogleGenAI({ apiKey });
        return this._client;
    }
    get credential() {
        return {
            url: this.options?.baseURL || process.env.GEMINI_BASE_URL,
            apiKey: this.options?.apiKey || process.env[this.apiKeyEnvName],
            model: this.options?.model || DEFAULT_MODEL,
        };
    }
    get modelOptions() {
        return this.options?.modelOptions;
    }
    /**
     * Process the input and generate a response
     * @param input The input to process
     * @returns The generated response
     */
    async process(input) {
        const model = input.model || this.credential.model;
        const responseFormat = input.responseFormat || "base64";
        if (responseFormat === "url") {
            throw new Error("Gemini image models currently only support base64 format");
        }
        if (model.includes("imagen")) {
            return this.generateImageByImagenModel(input);
        }
        return this.generateImageByGeminiModel(input);
    }
    async generateImageByImagenModel(input) {
        const model = input.model || this.credential.model;
        const mergedInput = { ...this.modelOptions, ...input };
        const inputKeys = [
            "seed",
            "safetyFilterLevel",
            "personGeneration",
            "outputMimeType",
            "outputGcsUri",
            "outputCompressionQuality",
            "negativePrompt",
            "language",
            "includeSafetyAttributes",
            "includeRaiReason",
            "imageSize",
            "guidanceScale",
            "aspectRatio",
            "addWatermark",
        ];
        const response = await this.client.models.generateImages({
            model: model,
            prompt: mergedInput.prompt,
            config: { numberOfImages: mergedInput.n || 1, ...(0, type_utils_js_1.pick)(mergedInput, inputKeys) },
        });
        return {
            images: response.generatedImages
                ?.map(({ image }) => (image?.imageBytes ? { base64: image.imageBytes } : undefined))
                .filter(type_utils_js_1.isNonNullable) || [],
            usage: {
                inputTokens: 0,
                outputTokens: 0,
            },
            model,
        };
    }
    async generateImageByGeminiModel(input) {
        const model = input.model || this.credential.model;
        const mergedInput = { ...this.modelOptions, ...input };
        const inputKeys = [
            "abortSignal",
            "audioTimestamp",
            "automaticFunctionCalling",
            "cachedContent",
            "frequencyPenalty",
            "httpOptions",
            "labels",
            "logprobs",
            "maxOutputTokens",
            "mediaResolution",
            "modelSelectionConfig",
            "presencePenalty",
            "responseJsonSchema",
            "responseLogprobs",
            "responseMimeType",
            "responseSchema",
            "routingConfig",
            "safetySettings",
            "seed",
            "speechConfig",
            "stopSequences",
            "systemInstruction",
            "temperature",
            "thinkingConfig",
            "toolConfig",
            "tools",
            "topK",
            "topP",
        ];
        const response = await this.client.models.generateContent({
            model: model,
            contents: input.prompt,
            config: {
                responseModalities: [genai_1.Modality.TEXT, genai_1.Modality.IMAGE],
                candidateCount: input.n || 1,
                ...(0, type_utils_js_1.pick)(mergedInput, inputKeys),
            },
        });
        const allImages = (response.candidates ?? [])
            .flatMap((candidate) => candidate.content?.parts ?? [])
            .filter((part) => part?.inlineData?.data)
            .map((part) => ({ base64: part.inlineData.data }));
        return {
            images: allImages,
            usage: {
                inputTokens: 0,
                outputTokens: 0,
            },
            model,
        };
    }
}
exports.GeminiImageModel = GeminiImageModel;
