import type { ChatModelInput } from "@aigne/core";
import { OpenAIChatModel, type OpenAIChatModelOptions } from "@aigne/openai";
/**
 * Implementation of the ChatModel interface for Google's Gemini API
 *
 * This model uses OpenAI-compatible API format to interact with Google's Gemini models,
 * providing access to models like Gemini 1.5 and Gemini 2.0.
 *
 * @example
 * Here's how to create and use a Gemini chat model:
 * {@includeCode ../test/gemini-chat-model.test.ts#example-gemini-chat-model}
 *
 * @example
 * Here's an example with streaming response:
 * {@includeCode ../test/gemini-chat-model.test.ts#example-gemini-chat-model-streaming}
 */
export declare class GeminiChatModel extends OpenAIChatModel {
    constructor(options?: OpenAIChatModelOptions);
    protected apiKeyEnvName: string;
    protected supportsToolsUseWithJsonSchema: boolean;
    protected supportsParallelToolCalls: boolean;
    protected supportsToolStreaming: boolean;
    getRunMessages(input: ChatModelInput): ReturnType<OpenAIChatModel["getRunMessages"]>;
}
