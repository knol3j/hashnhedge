import { ImageModel, type ImageModelInput, type ImageModelOptions, type ImageModelOutput } from "@aigne/core";
import { type Camelize } from "@aigne/core/utils/camelize.js";
import type OpenAI from "openai";
import type { ClientOptions } from "openai";
export interface OpenAIImageModelInput extends ImageModelInput, Camelize<Omit<OpenAI.ImageGenerateParams, "prompt" | "model" | "n" | "response_format">> {
}
export interface OpenAIImageModelOutput extends ImageModelOutput {
}
export interface OpenAIImageModelOptions extends ImageModelOptions<OpenAIImageModelInput, OpenAIImageModelOutput> {
    /**
     * API key for OpenAI API
     *
     * If not provided, will look for OPENAI_API_KEY in environment variables
     */
    apiKey?: string;
    /**
     * Base URL for OpenAI API
     *
     * Useful for proxies or alternate endpoints
     */
    baseURL?: string;
    /**
     * OpenAI model to use
     *
     * Defaults to 'dall-e-2'
     */
    model?: string;
    /**
     * Additional model options to control behavior
     */
    modelOptions?: Omit<Partial<OpenAIImageModelInput>, "model">;
    /**
     * Client options for OpenAI API
     */
    clientOptions?: Partial<ClientOptions>;
}
export declare class OpenAIImageModel extends ImageModel<OpenAIImageModelInput, OpenAIImageModelOutput> {
    options?: OpenAIImageModelOptions | undefined;
    constructor(options?: OpenAIImageModelOptions | undefined);
    protected _client?: OpenAI;
    protected apiKeyEnvName: string;
    get client(): OpenAI;
    get credential(): {
        url: string | undefined;
        apiKey: string | undefined;
        model: string;
    };
    get modelOptions(): Omit<Partial<OpenAIImageModelInput>, "model"> | undefined;
    /**
     * Process the input and generate a response
     * @param input The input to process
     * @returns The generated response
     */
    process(input: OpenAIImageModelInput): Promise<OpenAIImageModelOutput>;
}
